{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36318c92-2918-4ea4-a56c-4a8f8630aa0e",
   "metadata": {},
   "source": [
    "# **DSS Partial Order Resolution Probabilsitic Models**\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5037b71f-5c02-4ef7-8150-56eca15f2a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from pprint import pprint\n",
    "from itertools import chain, permutations, product\n",
    "from tqdm import tqdm\n",
    "import pm4py\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5bdadf-4b75-41e4-b847-55aba3377b3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1baf50f-59a9-445f-9543-61749f239529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# event set functions\n",
    "def pos_res_of_event_set(event_set: list) -> list:\n",
    "    \"\"\"For a given events set, returns the list of all possible resolutions.\"\"\"\n",
    "    \n",
    "    return [list(tup) for tup in permutations(event_set, len(event_set))]\n",
    "\n",
    "\n",
    "def pos_res_for_unc_trace(unc_trace: list) -> list:\n",
    "    \"\"\"Return all the possible resolution for an uncertain trace.\"\"\"\n",
    "        \n",
    "    resolutions_for_event_sets = [pos_res_of_event_set(unc_set) for unc_set in unc_trace]  # builds the pos_res for each event set in the trace, e.g. {C,B} -> [C,B] and [B,C]\n",
    "    \n",
    "    all_pos_res  = list(product(*resolutions_for_event_sets))  # builds all the pos res, i.e. all combinations of all the pos res for the event sets,\n",
    "                                                               # e.g. [[A], [[C,B], [B,C]], [D]] -> [A,B,C,D] and [A,C,B,D]\n",
    "\n",
    "    return [list(chain(*res)) for res in all_pos_res]  # make each pos res just a list of activities\n",
    "\n",
    "\n",
    "# time stamp functions\n",
    "def remove_timezones(log):\n",
    "    \"\"\" Takes the timezone offset of each timestamp and adds it to the timestamp + removes the timezone.\"\"\"\n",
    "    \n",
    "    for trace in log:\n",
    "        for event in trace:\n",
    "            tz_offset = event[\"time:timestamp\"].tzinfo.utcoffset(event[\"time:timestamp\"])\n",
    "            event[\"time:timestamp\"] = event[\"time:timestamp\"].replace(tzinfo=None) + tz_offset\n",
    "    return log\n",
    "\n",
    "def abstract_time(log, time_func):\n",
    "    \"\"\" Abstract the specified time level (in time_func) from the timestamps of the log.\n",
    "        Possible: time_func <-- abstract_{microseconds, seconds, minutes, hours, \n",
    "                                          day, month, year}.\n",
    "    \"\"\"\n",
    "    for trace in log:\n",
    "        for event in trace:\n",
    "            event[\"time:timestamp\"] = time_func(event[\"time:timestamp\"])\n",
    "\n",
    "def abstract_microseconds(timestamp: datetime.datetime) -> datetime.datetime:\n",
    "    return timestamp.replace(microsecond=0)\n",
    "\n",
    "def abstract_seconds(timestamp: datetime.datetime) -> datetime.datetime:\n",
    "    return timestamp.replace(second=0, microsecond=0)\n",
    "\n",
    "def abstract_minutes(timestamp: datetime.datetime) -> datetime.datetime:\n",
    "    return timestamp.replace(minute=0, second=0, microsecond=0)\n",
    "\n",
    "def abstract_hours(timestamp: datetime.datetime) -> datetime.datetime:\n",
    "    return timestamp.replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "def abstract_day(timestamp: datetime.datetime) -> datetime.datetime:\n",
    "    return timestamp.replace(day=1, hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "def abstract_month(timestamp: datetime.datetime) -> datetime.datetime:\n",
    "    return timestamp.replace(month=1, day=1, hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "def abstract_year(timestamp: datetime.datetime) -> datetime.datetime:\n",
    "    return timestamp.replace(year=1993, month=1, day=1, hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "def copy_timestamp(timestamp: datetime.datetime) -> datetime.datetime:\n",
    "    return timestamp.replace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012fb8e0-14c6-425b-a6d1-5cc898b9f0ad",
   "metadata": {},
   "source": [
    "Load and Preprocess Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "364db8a8-2f63-4fd6-a7d3-2b7c72f8e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define file path'\n",
    "\n",
    "bpic14     = \"./logs/BPI_Challenge_2014.xes\"\n",
    "traffic    = \"./logs/traffic_fines.xes\"\n",
    "artificial = \"./logs/1561989897313-3_75.xes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "895ac185-df31-47d7-bc98-67a77d7e1eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a125d80a06145399dfcaa0cb90f58b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/150370 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "event_log = pm4py.read_xes(traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb804a3c-0eb9-4a40-962b-8b54fe4a3439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the logs needs to be pre-processed\n",
    "\n",
    "# remove timezones \n",
    "log = remove_timezones(event_log)\n",
    "\n",
    "# abstract seconds for artificial log only\n",
    "#abstract_time(event_log, abstract_seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d8eff3-8260-44a2-843a-d179fefbd0dd",
   "metadata": {},
   "source": [
    "### Trace Equivalence Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6d8abc-0d2e-4c6b-9f8b-73ba9f617154",
   "metadata": {},
   "source": [
    "estimates the probability of a resolution by observing how often the given activity sequence is present in the certain log <br>\n",
    "two resolutions are equivalent, if they consist of the same sequence of executed activities <br>\n",
    "the certain log is defined as $ \\Sigma_{certain} = \\{ \\sigma \\in \\Sigma \\; \\vert \\; \\vert \\Phi(\\sigma) \\vert = 1 \\}$ <br>\n",
    "The probability of a resolution $\\phi \\in \\Phi(\\sigma)$ of a trace $\\sigma$ is then quantified as: \n",
    "$$ P_{trace}(\\phi) = \\frac{\\vert \\{ \\sigma \\in \\Sigma_{certain} \\; \\vert \\; \\exists \\phi' \\in \\Phi(\\sigma): \\phi' \\equiv \\phi \\} \\vert}{\\vert \\Sigma_{certain} \\vert} $$\n",
    "Note that $\\phi'$ in this case is the only resolution for $\\sigma$, since $\\sigma \\in \\Sigma_{certain}$ and thus $\\vert \\Phi(\\sigma) \\vert = 1$. <br>\n",
    "So for a given uncertain trace, the probability measures how often a particular resolution occurs in the certain log, i.e. the traces without order uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d3a4daf6-f202-404d-b3e6-0f8f23d97d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TraceEquivalenceModel():\n",
    "    \n",
    "    \n",
    "    def __init__(self, log):\n",
    "        self.NAME = \"concept:name\"\n",
    "        self.TIME = \"time:timestamp\"\n",
    "        \n",
    "        self.certain_log, self.uncertain_log, self.ground_truth_log = self.__split_and_sparse_log(log)\n",
    "        self.certain_trace_freq = self.__get_trace_frequencies()\n",
    "    \n",
    "    \n",
    "    def __split_and_sparse_log(self, log):\n",
    "        \"\"\"Extracts the certain part from a given log.\"\"\"\n",
    "        certain_log, uncertain_log, ground_truth_log = [], [], []\n",
    "        for trace in log:\n",
    "            if self.__trace_is_certain(trace):\n",
    "                sparse_trace = self.__get_sparse_trace(trace)\n",
    "                certain_log.append(sparse_trace)\n",
    "            else:\n",
    "                sparse_trace_set = self.__get_sparse_trace_set(trace)\n",
    "                uncertain_log.append(sparse_trace_set)\n",
    "                \n",
    "                sparse_trace = self.__get_sparse_trace(trace)  # get the ground truth according to gold standard\n",
    "                ground_truth_log.append(sparse_trace)          # i.e. order in the log\n",
    "        \n",
    "        return certain_log, uncertain_log, ground_truth_log\n",
    "    \n",
    "    \n",
    "    def __get_sparse_trace(self, trace):\n",
    "        \"\"\" Make a list of activities from the pm4py trace object. \"\"\"\n",
    "        sparse_trace = [event[self.NAME] for event in trace]\n",
    "        return sparse_trace\n",
    "    \n",
    "    \n",
    "    def __get_sparse_trace_set(self, trace) -> dict:\n",
    "        trace_set = dict()\n",
    "        for event in trace:\n",
    "            trace_set[str(event[self.TIME])] = trace_set.get(str(event[self.TIME]), []) + [event[self.NAME]]\n",
    "  \n",
    "        trace_set = [event_set for event_set in trace_set.values()]\n",
    "\n",
    "        return trace_set\n",
    "    \n",
    "    \n",
    "    def __trace_is_certain(self, trace):\n",
    "        \"\"\" Check if a trace is certain.\"\"\"\n",
    "        for i in range(len(trace)-1):\n",
    "            if trace[i][self.TIME] == trace[i+1][self.TIME]:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    \n",
    "    def __get_trace_frequencies(self):\n",
    "        trace_freq = {}\n",
    "        for trace in self.certain_log:\n",
    "            trace_freq[tuple(trace)] = trace_freq.get(tuple(trace), 0) + 1\n",
    "        return trace_freq\n",
    "\n",
    "\n",
    "    def P_trace(self, pos_res: list) -> float:\n",
    "        \"\"\"\n",
    "        Evaluates the probability of a possible resolution of a trace.\n",
    "\n",
    "        Input: Possible resolution (list) of a trace.\n",
    "\n",
    "        Returns: The probability for that given possible resolution.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.certain_trace_freq[tuple(pos_res)] / len(self.certain_log)\n",
    "        except:\n",
    "            #print(\"The certain trace does not contain this possible resolution. Probability undefined.\")\n",
    "            return 0\n",
    "    \n",
    "    \n",
    "    def eval_model(self):\n",
    "        correct_pred = 0\n",
    "        total_pred = len(self.ground_truth_log)  # 25502\n",
    "        for i in range(total_pred):\n",
    "            correct_pred += self.eval_uncertain_trace(self.uncertain_log[i], self.ground_truth_log[i], i)\n",
    "        \n",
    "        print()\n",
    "        print('Accuracy:', correct_pred / total_pred )\n",
    "                       \n",
    "        \n",
    "    def eval_uncertain_trace(self, unc_trace, truth_trace, i):\n",
    "        \"\"\" Determine the most probable possible resolution for a given uncertain trace. \"\"\"\n",
    "        pos_resolutions = pos_res_for_unc_trace(unc_trace)  \n",
    "        probs = [(pos_res, self.P_trace(pos_res)) for pos_res in pos_resolutions]  # get tuple (prob, pos_res) for each pos_res\n",
    "        del pos_resolutions  # need RAM\n",
    "        probs.sort(key=lambda tup: tup[1], reverse=True)\n",
    "        \n",
    "        pred_trace = probs[0][0]\n",
    "        prob = probs[0][1]\n",
    "        del probs  # need RAM\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(i, unc_trace, (pred_trace, prob), truth_trace)\n",
    "        \n",
    "        return pred_trace == truth_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cc8d36fd-fda9-4d18-8b5b-3b85d1b2d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_equiv_model = TraceEquivalenceModel(event_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "73cd50fd-5833-4be6-927b-7e04b364044d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506\n",
      "494\n",
      "494\n"
     ]
    }
   ],
   "source": [
    "print(len(trace_equiv_model.certain_log))\n",
    "print(len(trace_equiv_model.uncertain_log))\n",
    "print(len(trace_equiv_model.ground_truth_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "80099e54-7a79-4f29-b038-d5effeda1aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [['tau split8'], ['a10', 'tau join9'], ['g12'], ['c13'], ['e14'], ['f15', 'd16']] (['tau split8', 'a10', 'tau join9', 'g12', 'c13', 'e14', 'f15', 'd16'], 0.003952569169960474) ['tau split8', 'a10', 'tau join9', 'g12', 'c13', 'e14', 'f15', 'd16']\n",
      "\n",
      "Accuracy: 0.631578947368421\n"
     ]
    }
   ],
   "source": [
    "trace_equiv_model.eval_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a99c2-e22a-4b87-a271-f826749b73ec",
   "metadata": {},
   "source": [
    "### N-Gram Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99af7d31-e5d5-4017-baf4-01a6ee67236e",
   "metadata": {},
   "source": [
    "approach based on $N-gram$ $approximation$ <br> \n",
    "given a resolution $\\phi = \\langle a_1, ..., a_n \\rangle $ at first for each activity the respective probability to be at that position in the trace / pos res is estimated <br> \n",
    "for the pos res $\\phi_1 = \\langle a, b, c, d, f, g\\rangle $ and $N = 4$ the likeliness of the activity sequence $\\langle b, c, d \\rangle$ being followed by $f$. <br>\n",
    "the predicate $certain$ in this case for an activity sequence $A = \\langle a_1, ..., a_m\\rangle$ and a trace $\\sigma = E_1, ..., E_n \\rangle$ holds, iff the trace contains the respective activity sequence without order uncertainty ($m \\leq n$)\n",
    "$$certain(A, \\sigma) \\iff \\exists \\; i \\in \\{0, ..., n-m \\}, \\forall \\; j \\in \\{ 1, ..., m \\}: \\;\\; E_{i+j} = \\{e_{i+j}\\} \\land \\lambda(e_{i+j}) = a_j$$\n",
    "The probability of an acitvity a to follow an activity sequence A is then defined as the fraction traces in the log where the sequence is (not) followed by a:\n",
    "$$P(a \\; \\vert \\langle a_1, ..., a_m\\rangle = \\frac{\\vert \\{ \\sigma \\in \\Sigma \\; \\vert \\; certain(\\langle a_1, ..., a_m, a\\rangle, \\sigma) \\} \\vert}{\\vert \\{ \\sigma \\in \\Sigma \\; \\vert \\; certain(\\langle a_1, ..., a_m \\rangle, \\sigma) \\} \\vert} $$ \n",
    "based thereon, the n-gram probability for a possible resolution $\\phi = \\langle e_1, ..., e_n \\rangle$ aggregates the probabilities of all its events:\n",
    "$$P_{N-gram}(\\phi) = \\prod_{k=2}^{n} P( \\; \\lambda(e_k) \\; \\vert \\; \\langle \\lambda(e_{max(1, k-N+1)}), ..., \\lambda(e_{k-1}) \\rangle \\;) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8d1cdf3-981a-4eb6-b17c-1be04eef6336",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramModel():\n",
    "\n",
    "    \n",
    "    def __init__(self, log):\n",
    "        self.NAME = \"concept:name\"\n",
    "        self.TIME = \"time:timestamp\"\n",
    "        \n",
    "        self.log = log\n",
    "        self.log_set = self.__make_log_set()\n",
    "\n",
    "        self.certain_sequences = [self.__make_certain_sequences(trace_set) for trace_set in self.log_set]\n",
    "        \n",
    "        self.uncertain_log, self.ground_truth_log = self.__split_and_sparse_log(log)\n",
    "\n",
    "    \n",
    "    def __make_log_set(self) -> list:\n",
    "        log_set = []\n",
    "        for trace in self.log:\n",
    "            log_set.append(self.__make_trace_sets(trace))\n",
    "        return log_set\n",
    "\n",
    "    \n",
    "    def __make_trace_sets(self, trace) -> dict:\n",
    "        trace_set = dict()\n",
    "        for event in trace:\n",
    "            trace_set[str(event[self.TIME])] = trace_set.get(str(event[self.TIME]), []) + [event[self.NAME]]\n",
    "        return trace_set\n",
    "\n",
    "    \n",
    "    def __make_certain_sequences(self, trace_set) -> list:\n",
    "        '''\n",
    "        For each uncertain trace we cut out the certain subtraces, e.g. [{1}, {2,3}, {4}, {5}] -> [[1],[4,5]]\n",
    "        And in those we search for an activity sequence to be present\n",
    "        Because for an activity sequence to be certain in a trace it must apper in a certain sequence of a trace\n",
    "        '''\n",
    "        certain_sequences = []\n",
    "        certain_sequence = []\n",
    "        for i, timestamp in enumerate(trace_set):\n",
    "            if len(trace_set[timestamp]) == 1:\n",
    "                if i == len(trace_set)-1:\n",
    "                    certain_sequence.append(trace_set[timestamp][0])\n",
    "                    certain_sequences.append(certain_sequence)\n",
    "                else:\n",
    "                    certain_sequence.append(trace_set[timestamp][0])\n",
    "            else:\n",
    "                if certain_sequence:\n",
    "                    certain_sequences.append(certain_sequence)\n",
    "                certain_sequence = []\n",
    "        return certain_sequences\n",
    "    \n",
    "    \n",
    "    def __split_and_sparse_log(self, log):\n",
    "        \"\"\"Prepare the data for evaluation, i.e. the uncertain log and corresponding ground truth.\"\"\"\n",
    "        \n",
    "        uncertain_log, ground_truth_log = [], []\n",
    "        for trace in log:\n",
    "            if not self.__trace_is_certain(trace):\n",
    "                sparse_trace_set = self.__get_sparse_trace_set(trace)\n",
    "                uncertain_log.append(sparse_trace_set)\n",
    "\n",
    "                sparse_trace = self.__get_sparse_trace(trace)  # get the ground truth according to gold standard\n",
    "                ground_truth_log.append(sparse_trace)          # i.e. order in the log\n",
    "\n",
    "        return uncertain_log, ground_truth_log\n",
    "    \n",
    "    \n",
    "    def __get_sparse_trace(self, trace):\n",
    "        \"\"\" Make a list of activities from the pm4py trace object. \"\"\"\n",
    "        sparse_trace = [event[self.NAME] for event in trace]\n",
    "        return sparse_trace\n",
    "    \n",
    "    \n",
    "    def __get_sparse_trace_set(self, trace) -> dict:\n",
    "        trace_set = dict()\n",
    "        for event in trace:\n",
    "            trace_set[str(event[self.TIME])] = trace_set.get(str(event[self.TIME]), []) + [event[self.NAME]]\n",
    "  \n",
    "        trace_set = [event_set for event_set in trace_set.values()]\n",
    "\n",
    "        return trace_set\n",
    "    \n",
    "    \n",
    "    def __trace_is_certain(self, trace):\n",
    "        \"\"\" Check if a trace is certain.\"\"\"\n",
    "        for i in range(len(trace)-1):\n",
    "            if trace[i][self.TIME] == trace[i+1][self.TIME]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    \n",
    "    def __activities_in_sequence(self, activity_sequence: list, certain_sequence: list) -> bool:\n",
    "        for i in range(len(certain_sequence) - len(activity_sequence) + 1):\n",
    "            if certain_sequence[i:i+len(activity_sequence)] == activity_sequence:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    \n",
    "    def certain(self, activity_sequence: list, trace_set: dict) -> bool:\n",
    "        certain_sequences = self.__make_certain_sequences(trace_set)\n",
    "        for certain_sequence in certain_sequences:\n",
    "            if self.__activities_in_sequence(activity_sequence, certain_sequence):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    def P_a_activity_sequence(self, activity: str, activity_sequence: list) -> float:\n",
    "        n_sequence_plus_activity_is_certain = 0\n",
    "        n_sequence_is_certain = 0\n",
    "        \n",
    "        for trace_set in self.log_set:\n",
    "            if self.certain(activity_sequence, trace_set):\n",
    "                n_sequence_is_certain += 1\n",
    "                if self.certain(activity_sequence + [activity], trace_set):\n",
    "                    n_sequence_plus_activity_is_certain += 1\n",
    "        \n",
    "        if n_sequence_is_certain == 0: \n",
    "            return 0\n",
    "        return n_sequence_plus_activity_is_certain/n_sequence_is_certain\n",
    "\n",
    "    \n",
    "    def P_n_gram(self, pos_res: list, n: int=2):\n",
    "        #possible_resolution like [a, b, c]\n",
    "        lower_bound = 1         # 2 in the paper, but indexing here starts one before\n",
    "        upper_bound = len(pos_res)\n",
    "        result = 1.0\n",
    "        for i in range(lower_bound,upper_bound):\n",
    "            s_index = max(i-n+1, 0)         #the gram is not n long in the beginning, its 2 long, then 3, ... until it's always n long\n",
    "            result *= self.P_a_activity_sequence(pos_res[i], pos_res[s_index:i])\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def eval_model(self, n: int=2):\n",
    "        correct_pred = 0\n",
    "        total_pred = len(self.ground_truth_log)  # bpic14: 25502\n",
    "        \n",
    "        for i in tqdm(range(total_pred)):\n",
    "            correct_pred += self.eval_uncertain_trace(self.uncertain_log[i], self.ground_truth_log[i], n, i)\n",
    "        \n",
    "        print()\n",
    "        print('Accuracy:', correct_pred / total_pred )\n",
    "                       \n",
    "        \n",
    "    def eval_uncertain_trace(self, unc_trace, truth_trace, n, i):\n",
    "        \"\"\" Determine the most probable possible resolution for a given uncertain trace. \"\"\"\n",
    "        \n",
    "        pos_resolutions = pos_res_for_unc_trace(unc_trace)  \n",
    "        probs = [(pos_res, self.P_n_gram(pos_res, n)) for pos_res in pos_resolutions]  # get tuple (prob, pos_res) for each pos_res\n",
    "        probs.sort(key=lambda tup: tup[1], reverse=True)\n",
    "        \n",
    "        pred_trace = probs[0][0]\n",
    "        prob = probs[0][1]\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(i, unc_trace, (pred_trace, prob), truth_trace)\n",
    "        \n",
    "        return pred_trace == truth_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99c6476d-978e-4bbf-866b-b4d932b34c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_model = NGramModel(event_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca618be7-5ee2-4d42-81d6-a0280385c7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150370\n",
      "150370\n",
      "9166\n",
      "9166\n"
     ]
    }
   ],
   "source": [
    "print(len(n_gram_model.log))\n",
    "print(len(n_gram_model.log_set))\n",
    "print(len(n_gram_model.uncertain_log))\n",
    "print(len(n_gram_model.ground_truth_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e8014a-f2cb-401b-a866-264a3df6cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_model.eval_model(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a24111-fe57-49e6-94b9-c2b4fb7c07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(2,5):\n",
    "    print('Running experiment on N =', n)\n",
    "    n_gram_model.eval_model(n)\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf3ec1c-d720-42b2-b4a8-787c3bdf17c9",
   "metadata": {},
   "source": [
    "### Weak Order Model\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7008ebfa-c8de-4755-ac99-99f8d55ffe11",
   "metadata": {},
   "source": [
    "estimates the probabilities determining the fraction of traces an event related to some activity $a$ occurs at some point before another activity $b$ <br>\n",
    "formally the predicate $order$ describes whether or not a trace $\\sigma = \\langle E_1, ..., E_n \\rangle$ contains two activities $a$ and $b$ in weak order:\n",
    "$$order(a, b, \\sigma) \\iff \\exists \\; i,j : \\;\\;\\; e_i \\in E_i \\land e_j \\in E_j \\land \\lambda(e_i) = a \\land \\lambda(e_j) = b \\land i < j \\;\\;\\;\\; i,j \\in \\{1, ..., n\\}$$\n",
    "$order$ allows to estimate a probability for specific activity executions in weak order by considering the ratio of traces that contain the respective events:\n",
    "$$P(a, b) = \\frac{\\vert \\{ \\sigma \\in \\Sigma \\;\\; \\vert \\;\\; order(a, b, \\sigma) \\} \\vert}{\\vert \\{ \\sigma \\in \\Sigma \\;\\; \\vert \\;\\; \\exists e, e' \\in E_\\sigma : \\; \\lambda(e) = a \\land \\lambda(e') = b \\} \\vert}$$\n",
    "with that the probability of a possible resolution $\\phi = \\langle e_1, ..., e_n \\rangle$ is the computed by aggregating the probabilities of all pairs of events to occur in the particular order:\n",
    "$$P_{WO}(\\phi) = \\prod_{\\substack{1 \\leq i < n \\\\ i < j \\leq n}} P(\\lambda(e_i), \\lambda(e_j))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "934a7a95-8fab-4b31-b9ef-d5a7d192e282",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeakOrderModel():\n",
    "\n",
    "    def __init__(self, log):\n",
    "        self.NAME = \"concept:name\"\n",
    "        self.TIME = \"time:timestamp\"\n",
    "        \n",
    "        self.log = log\n",
    "        self.log_set = self.__make_log_set()  # log set is a list of traces, where each trace is a dict of (timestamps, events) key-value-pairs\n",
    "        \n",
    "        self.uncertain_log, self.ground_truth_log = self.__split_and_sparse_log(log)\n",
    "    \n",
    "    \n",
    "    def __make_log_set(self) -> list:\n",
    "        log_set = []\n",
    "        for trace in self.log:\n",
    "            log_set.append(self.__make_trace_sets(trace))\n",
    "        return log_set\n",
    "\n",
    "    \n",
    "    def __make_trace_sets(self, trace) -> dict:\n",
    "        trace_set = dict()\n",
    "        for event in trace:\n",
    "            trace_set[str(event[self.TIME])] = trace_set.get(str(event[self.TIME]), []) + [event[self.NAME]]\n",
    "        return trace_set\n",
    "    \n",
    "    \n",
    "    def __split_and_sparse_log(self, log):\n",
    "        \"\"\"Prepare the data for evaluation, i.e. the uncertain log and corresponding ground truth.\"\"\"\n",
    "        \n",
    "        uncertain_log, ground_truth_log = [], []\n",
    "        for trace in log:\n",
    "            if not self.__trace_is_certain(trace):\n",
    "                sparse_trace_set = self.__get_sparse_trace_set(trace)\n",
    "                uncertain_log.append(sparse_trace_set)\n",
    "\n",
    "                sparse_trace = self.__get_sparse_trace(trace)  # get the ground truth according to gold standard\n",
    "                ground_truth_log.append(sparse_trace)          # i.e. order in the log\n",
    "\n",
    "        return uncertain_log, ground_truth_log\n",
    "    \n",
    "    \n",
    "    def __get_sparse_trace(self, trace):\n",
    "        \"\"\" Make a list of activities from the pm4py trace object. \"\"\"\n",
    "        sparse_trace = [event[self.NAME] for event in trace]\n",
    "        return sparse_trace\n",
    "    \n",
    "    \n",
    "    def __get_sparse_trace_set(self, trace) -> dict:\n",
    "        trace_set = dict()\n",
    "        for event in trace:\n",
    "            trace_set[str(event[self.TIME])] = trace_set.get(str(event[self.TIME]), []) + [event[self.NAME]]\n",
    "  \n",
    "        trace_set = [event_set for event_set in trace_set.values()]\n",
    "\n",
    "        return trace_set\n",
    "    \n",
    "    \n",
    "    def __trace_is_certain(self, trace):\n",
    "        \"\"\" Check if a trace is certain.\"\"\"\n",
    "        for i in range(len(trace)-1):\n",
    "            if trace[i][self.TIME] == trace[i+1][self.TIME]:\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    \n",
    "    def order(self, a: str, b: str, trace_set) -> bool:\n",
    "        \"\"\"Check whether a trace contains activity a before activity b.\"\"\"\n",
    "        \n",
    "        trace_list = [event_set for timestamp, event_set in trace_set.items()]\n",
    "        for i in range(len(trace_list)-1):\n",
    "            if a in trace_list[i]:\n",
    "                for j in range(i+1, len(trace_list)):\n",
    "                    if b in trace_list[j]:\n",
    "                        return True\n",
    "        return False\n",
    "\n",
    "    \n",
    "    def contains_activities(self, a: str, b: str, trace_set) -> bool:\n",
    "        \"\"\"Check whether a trace contains the activities a and b.\"\"\"\n",
    "        \n",
    "        activities = [a for event_set in trace_set.values() for a in event_set]\n",
    "        return (a in activities and b in activities)\n",
    "\n",
    "\n",
    "    def P_a_b(self, a: str, b: str) -> float:\n",
    "        \"\"\"Computes the probability of activity a and b to occur in weak order.\"\"\"\n",
    "        \n",
    "        n_traces_with_a_b_in_weak_order = 0\n",
    "        n_traces_with_a_b = 0\n",
    "        \n",
    "        for trace_set in self.log_set:\n",
    "            if self.contains_activities(a, b, trace_set):\n",
    "                n_traces_with_a_b += 1\n",
    "                if self.order(a, b, trace_set):\n",
    "                    n_traces_with_a_b_in_weak_order += 1\n",
    "        \n",
    "        if n_traces_with_a_b == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return n_traces_with_a_b_in_weak_order / n_traces_with_a_b\n",
    "\n",
    "    \n",
    "    def P_weak_order(self, pos_res: list) -> float:\n",
    "        \"\"\"Compute the probability of a possible resolution accorind to the weak order model.\"\"\"\n",
    "        \n",
    "        result = 1.0\n",
    "        \n",
    "        for i in range(len(pos_res)-1):\n",
    "            for j in range(i+1, len(pos_res)):\n",
    "                result *= self.P_a_b(pos_res[i], pos_res[j])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def eval_model(self):\n",
    "        correct_pred = 0\n",
    "        total_pred = len(self.ground_truth_log)  # bpic14: 25502\n",
    "        \n",
    "        for i in range(total_pred):\n",
    "            if i%1 == 0: print(i)\n",
    "            correct_pred += self.eval_uncertain_trace(self.uncertain_log[i], self.ground_truth_log[i], i)\n",
    "        \n",
    "        print()\n",
    "        print('Accuracy:', correct_pred / total_pred )\n",
    "                       \n",
    "        \n",
    "    def eval_uncertain_trace(self, unc_trace, truth_trace, i):\n",
    "        \"\"\" Determine the most probable possible resolution for a given uncertain trace. \"\"\"\n",
    "        \n",
    "        pos_resolutions = pos_res_for_unc_trace(unc_trace)  \n",
    "        probs = [(pos_res, self.P_weak_order(pos_res)) for pos_res in pos_resolutions]  # get tuple (prob, pos_res) for each pos_res\n",
    "        probs.sort(key=lambda tup: tup[1], reverse=True)\n",
    "        \n",
    "        pred_trace = probs[0][0]\n",
    "        prob = probs[0][1]\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(i, unc_trace, (pred_trace, prob), truth_trace)\n",
    "        \n",
    "        return pred_trace == truth_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ba6c7458-29d7-405e-845d-ae5248e9a96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_order_model = WeakOrderModel(event_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "87244a83-37a4-444d-8610-0bf6eb9dbf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "494\n",
      "494\n"
     ]
    }
   ],
   "source": [
    "print(len(weak_order_model.log))\n",
    "print(len(weak_order_model.uncertain_log))\n",
    "print(len(weak_order_model.ground_truth_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0f52234b-670a-48e8-934b-903fb032d840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0 [['tau split8'], ['a10', 'tau join9'], ['g12'], ['c13'], ['e14'], ['f15', 'd16']] (['tau split8', 'a10', 'tau join9', 'g12', 'c13', 'e14', 'f15', 'd16'], 0.019361725780867273) ['tau split8', 'a10', 'tau join9', 'g12', 'c13', 'e14', 'f15', 'd16']\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "100 [['a2'], ['h3'], ['tau join1'], ['g4', 'tau split0', 'tau split0'], ['b6'], ['d7'], ['c5']] (['a2', 'h3', 'tau join1', 'g4', 'tau split0', 'tau split0', 'b6', 'd7', 'c5'], 0.0) ['a2', 'h3', 'tau join1', 'g4', 'b6', 'd7', 'tau split0', 'tau split0', 'c5']\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "200 [['tau split8'], ['a10'], ['h11'], ['tau join9'], ['g12'], ['c13'], ['e14'], ['f15', 'd16']] (['tau split8', 'a10', 'h11', 'tau join9', 'g12', 'c13', 'e14', 'f15', 'd16'], 0.003580422533388935) ['tau split8', 'a10', 'h11', 'tau join9', 'g12', 'c13', 'e14', 'f15', 'd16']\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "300 [['tau split8'], ['a10'], ['h11', 'h11'], ['g12'], ['c13', 'e14'], ['tau join9'], ['f15'], ['d16']] (['tau split8', 'a10', 'h11', 'h11', 'g12', 'c13', 'e14', 'tau join9', 'f15', 'd16'], 0.0) ['tau split8', 'a10', 'h11', 'h11', 'g12', 'c13', 'e14', 'tau join9', 'f15', 'd16']\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "400 [['e14'], ['tau split8', 'tau split8'], ['a10'], ['tau join9', 'g12'], ['c13'], ['h11'], ['f15'], ['d16']] (['e14', 'tau split8', 'tau split8', 'a10', 'tau join9', 'g12', 'c13', 'h11', 'f15', 'd16'], 0.0) ['e14', 'tau split8', 'a10', 'tau join9', 'g12', 'c13', 'h11', 'f15', 'd16', 'tau split8']\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "\n",
      "Accuracy: 0.5303643724696356\n"
     ]
    }
   ],
   "source": [
    "weak_order_model.eval_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
